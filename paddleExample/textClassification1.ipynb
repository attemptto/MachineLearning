{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from multiprocessing import cpu_count\n",
    "import numpy as np\n",
    "import shutil\n",
    "import paddle\n",
    "import paddle.fluid as fluid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def create_data_list(data_root_path):\n",
    "    #创建test_list 和 train_list\n",
    "    with open(data_root_path+'test_list.txt','w') as f:\n",
    "        pass\n",
    "    with open(data_root_path+'train_list.txt','w') as f:\n",
    "        pass\n",
    "\n",
    "    with open(os.path.join(data_root_path,'dict_txt.txt'),'r',encoding='utf-8') as f_data:\n",
    "        dict_txt = eval(f_data.readlines()[0])\n",
    "\n",
    "    with open(os.path.join(data_root_path,'news_classify_data.txt'),'r',encoding='utf-8') as f_data:\n",
    "        lines = f_data.readlines()\n",
    "    i = 0\n",
    "    for lines in lines:\n",
    "        title = lines.split('_!_')[-1].replace('\\n','')\n",
    "        l = lines.split('_!_')[1]\n",
    "        labs = \"\"\n",
    "        if i %10 == 0:\n",
    "            with open(os.path.join(data_root_path,'test_list.txt'),'a',encoding='utf-8') as f_test:\n",
    "                for s in title:\n",
    "                    lab = str(dict_txt[s])\n",
    "                    labs = labs + lab + ','\n",
    "                labs = labs[:-1]\n",
    "                labs = labs + '\\t' + l + '\\n'\n",
    "                f_test.write(labs)\n",
    "        else:\n",
    "            with open(os.path.join(data_root_path,'train_list.txt'),'a',encoding='utf-8') as f_train:\n",
    "                for s in title:\n",
    "                    lab = str(dict_txt[s])\n",
    "                    labs = labs + lab + ','\n",
    "                labs = labs[:-1]\n",
    "                labs = labs + '\\t' + l + '\\n'\n",
    "                f_train.write(labs)\n",
    "        i+=1\n",
    "    print(\"数据列表生成完成\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def create_dict(data_path, dict_path):\n",
    "    dict_set = set()\n",
    "\n",
    "    with open(data_path,'r',encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        title = line.split('_!_')[-1].replace('\\n','')\n",
    "        for s in title:\n",
    "            dict_set.add(s)\n",
    "\n",
    "    dict_list = []\n",
    "    i = 0\n",
    "    for s in dict_set:\n",
    "        dict_list.append([s, i])\n",
    "        i+=1\n",
    "    dict_txt = dict(dict_list)\n",
    "    end_dict = {\"<unk>\": i}\n",
    "    dict_txt.update(end_dict)\n",
    "    with open(dict_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(str(dict_txt))\n",
    "\n",
    "    print(\"数据字典生成完成\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#获取字典长度\n",
    "def get_dict_len(dic_path):\n",
    "    with open(dic_path,'r',encoding='utf-8') as f:\n",
    "        line = eval(f.readlines()[0])\n",
    "    return len(line.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据字典生成完成\n",
      "数据列表生成完成\n"
     ]
    }
   ],
   "source": [
    "data_root_path = 'dataset1/'\n",
    "data_path = os.path.join(data_root_path,'news_classify_data.txt')\n",
    "dict_path = os.path.join(data_root_path,'dict_txt.txt')\n",
    "\n",
    "create_dict(data_path,dict_path)\n",
    "create_data_list(data_root_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#训练、测试数据的预处理\n",
    "def data_mapper(sample):\n",
    "    data,label = sample\n",
    "    data = [int(data) for data in data.split(',')]\n",
    "    return data,int(label)\n",
    "\n",
    "def train_reader(train_list_path):\n",
    "    def reader():\n",
    "        with open(train_list_path,'r') as f:\n",
    "            lines = f.readlines()\n",
    "            np.random.shuffle(lines)\n",
    "            for line in lines:\n",
    "                data, label = line.split('\\t')\n",
    "                yield data,label\n",
    "    return paddle.reader.xmap_readers(data_mapper,reader,cpu_count,1024)\n",
    "\n",
    "#创建数据读取器：\n",
    "def test_reader(test_list_path):\n",
    "    def reader():\n",
    "        with open(test_list_path,'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                data, label = line.split('/t')\n",
    "                yield data,label\n",
    "    return paddle.reader.xmap_readers(data_mapper,reader,cpu_count,1024)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#创建卷积神经网络\n",
    "def CNN_net(data,dict_dim,class_dim=10,emb_dim=128,hid_dim=128,hid_dim2=98):\n",
    "    #embedding\n",
    "    emb = fluid.layers.embedding(input=data,size=[dict_dim,emb_dim])\n",
    "\n",
    "    #\n",
    "    conv_3 = fluid.nets.sequence_conv_pool(input=emb,num_filters=hid_dim,filter_size=3,act='tanh',pool_type='sqrt')\n",
    "\n",
    "    conv_4 = fluid.nets.sequence_conv_pool(input=emb,num_filters=hid_dim2,filter_size=4,act='tanh',pool_type='sqrt')\n",
    "\n",
    "    output = fluid.layers.fc(input=[conv_3,conv_4],size=class_dim,act='softmax')\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#   正确的label\n",
    "paddle.enable_static()\n",
    "\n",
    "words = fluid.layers.data(name='words',shape=[1],dtype='int64',lod_level=1)\n",
    "label = fluid.layers.data(name='label',shape=[1],dtype='int64')\n",
    "\n",
    "dict_dim = get_dict_len('dataset1/dict_txt.txt')\n",
    "\n",
    "model = CNN_net(words,dict_dim=dict_dim)\n",
    "#计算损失\n",
    "cost = fluid.layers.cross_entropy(input=model,label=label)\n",
    "\n",
    "avg_cost = fluid.layers.mean(cost)\n",
    "\n",
    "acc = fluid.layers.accuracy(input=model, label=label)\n",
    "\n",
    "#预测程序,测试集上run\n",
    "test_program = fluid.default_main_program().clone(for_test=True)\n",
    "\n",
    "#优化方法\n",
    "optimizer = fluid.optimizer.AdagradOptimizer(learning_rate=0.002)\n",
    "opt = optimizer.minimize(avg_cost)\n",
    "\n",
    "place = fluid.CUDAPlace(0)\n",
    "\n",
    "exe = fluid.Executor(place)\n",
    "\n",
    "exe.run(fluid.default_startup_program())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_reader = paddle.batch(reader=train_reader('dataset1/train_list.txt'),batch_size=30)\n",
    "test_reader = paddle.batch(reader=test_reader('dataset1/test_list.txt'),batch_size=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%训练集，测试集 数据读取器\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "feeder = fluid.DataFeeder(place=place,feed_list=[words,label])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-11-a2074a650edb>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;31m#开始训练\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mpass_id\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mepochs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m     \u001B[1;32mfor\u001B[0m \u001B[0mbatch_id\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdata\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_reader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m         train_cost,train_acc = exe.run(program=fluid.default_main_program(),\n\u001B[0;32m      7\u001B[0m                                        \u001B[0mfeed\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfeeder\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeed\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\paddle\\batch.py\u001B[0m in \u001B[0;36mbatch_reader\u001B[1;34m()\u001B[0m\n\u001B[0;32m     56\u001B[0m         \u001B[0mr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mreader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     57\u001B[0m         \u001B[0mb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 58\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0minstance\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mr\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     59\u001B[0m             \u001B[0mb\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minstance\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\paddle\\reader\\decorator.py\u001B[0m in \u001B[0;36mxreader\u001B[1;34m()\u001B[0m\n\u001B[0;32m    481\u001B[0m             in_queue, out_queue, mapper)\n\u001B[0;32m    482\u001B[0m         \u001B[0mworkers\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 483\u001B[1;33m         \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mprocess_num\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    484\u001B[0m             \u001B[0mworker\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mThread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtarget\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    485\u001B[0m             \u001B[0mworker\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdaemon\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'method' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "model_save_dir = '/dataset1/infer_model/'\n",
    "#开始训练\n",
    "for pass_id in range(epochs):\n",
    "    for batch_id,data in enumerate(train_reader()):\n",
    "        train_cost,train_acc = exe.run(program=fluid.default_main_program(),\n",
    "                                       feed=feeder.feed(data),\n",
    "                                       fetch_list=[avg_cost,acc])\n",
    "        if batch_id%100 == 0:\n",
    "            print('pass :%d, Batch:%d, Cost:%d, Acc:%0.5f'%(pass_id, batch_id, train_cost[0],train_acc[0]))\n",
    "\n",
    "    test_costs = []\n",
    "    test_accs = []\n",
    "    for batch_id,data in enumerate(test_reader()):\n",
    "        test_cost,test_acc = exe.run(program=test_program,\n",
    "                                     feed=feeder.feed(data),\n",
    "                                     fetch_list=[avg_cost,acc])\n",
    "        test_costs.append(test_cost[0])\n",
    "        test_accs.append(test_acc[0])\n",
    "\n",
    "    #计算平局损失和预测率\n",
    "    test_cost = (sum(test_costs)/len(test_costs))\n",
    "    test_acc = (sum(test_accs)/len(test_accs))\n",
    "    print('Test:%d,Cost:%0.5f, ACC:%0.5f'%(pass_id, test_cost,test_acc))\n",
    "\n",
    "if not os.path.exists(model_save_dir):\n",
    "    os.makedirs(model_save_dir)\n",
    "fluid.io.save_inference_model(model_save_dir,feeded_var_names=[words.name],\n",
    "                              target_vars=[model],executor=exe)\n",
    "print(\"训练模型保存完成\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}